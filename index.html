<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for SEO and social sharing -->
  <meta name="description" content="Demo page for the paper 'MGE-LDM: A Unified Latent Diffusion Model for Music Generation, Source Imputation, and Query-Driven Source Separation' by Yunkee Chae and Kyogu Lee. Explore audio samples, code, and resources.">
  <meta name="keywords" content="MGE-LDM, Music Generation, Latent Diffusion Model, Source Imputation, Source Separation, Audio AI, Music AI, Yunkee Chae, Kyogu Lee, Seoul National University, Demo, Research">
  <meta name="author" content="Yunkee Chae, Kyogu Lee">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Open Graph for social media (Facebook, LinkedIn, etc.) -->
  <meta property="og:title" content="MGE-LDM: A Unified Latent Diffusion Model for Music Generation, Source Imputation, and Query-Driven Source Separation"/>
  <meta property="og:description" content="Listen to audio samples and explore resources for MGE-LDM, a novel model for music generation and source separation. Presented by Yunkee Chae and Kyogu Lee (Seoul National University)."/>
  <meta property="og:url" content="https://yoongi43.github.io/MGELDM_Samples"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/figs_overall.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="MGE-LDM: Latent Diffusion for Music Generation and Source Separation">
  <meta name="twitter:description" content="Demo and resources for MGE-LDM, a unified model for music generation, imputation, and separation.">
  <meta name="twitter:image" content="https://yoongi43.github.io/MGELDM_Samples/static/images/figs_overall.png">
  <meta name="twitter:site" content="@ygch43">



  <title>MGE-LDM</title>
  <link rel="icon" type="image/x-icon" href="static/images/music_favicon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <link rel="stylesheet" href="https://cdn.plyr.io/3.7.8/plyr.css" />
  <script src="https://cdn.plyr.io/3.7.8/plyr.polyfilled.js"></script>
  <style>
    /* 보라색 버튼 (#996699) */
    .btn-purple {
      background: #996699 !important;
      color: #fff !important;
      border: none !important;
    }
    .btn-purple:hover, .btn-purple:focus {
      background: #7d5682 !important; /* 조금 더 진한 보라색 (hover) */
      color: #fff !important;
    }

    /* 노란색 버튼 (#FFCC33) */
    .btn-yellow {
      background: #FFCC33 !important;
      color: #333 !important;
      border: none !important;
    }
    .btn-yellow:hover, .btn-yellow:focus {
      background: #e6b800 !important; /* 진한 노랑 (hover) */
      color: #222 !important;
    }

    /* 빨간색 버튼 (#FF6666) */
    .btn-red {
      background: #FF6666 !important;
      color: #fff !important;
      border: none !important;
    }
    .btn-red:hover, .btn-red:focus {
      background: #cc3333 !important; /* 진한 빨강 (hover) */
      color: #fff !important;
    }
    .plyr audio,
    .plyr__controls {
      min-width: 80px;  /* 플레이어 폭, 더 줄이고 싶으면 수정 */
      max-width: 100px;
    }

    /* 분홍빛 퍼플(Magenta) 버튼 */
    .btn-magenta {
      background: #CC33CC;
      color: #fff;
      border: none;
    }
    .btn-magenta:hover,
    .btn-magenta:focus {
      background: #AA00AA;
      color: #fff;
    }
  </style>
</head>

<body>
    <section class="hero">
        <div class="hero-body">
          <div class="container is-max-desktop">
            <div class="columns is-centered">
              <div class="column has-text-centered">
                <h1 class="title is-1 publication-title">MGE-LDM: Simultaneous Music Generation and Extraction via Joint Latent Modeling</h1>
                <div class="is-size-5 publication-authors">
                  <!-- Paper authors -->
                  <span class="author-block">
                    <!-- <a href="FIRST AUTHOR PERSONAL LINK" target="_blank"></a><sup>*</sup>,</span> -->
                    <!-- <a href="FIRST AUTHOR PERSONAL LINK" target="_blank"></a>Yunkee Chae and Kyogu Lee</span> -->
                    <!-- <span class="author-block">
                      <a href="SECOND AUTHOR PERSONAL LINK" target="_blank"></a><sup>*</sup>,</span> -->
                      <a href="https://yoongi43.github.io/" target="_blank">Yunkee Chae<sup>1,2</sup></a> and 
                      <a href="https://scholar.google.com/citations?user=Fk4jQFEAAAAJ&hl=en" target="_blank">Kyogu Lee<sup>1,2,3,4</sup></a>
                      </span>
                      </div>
    
                      <div class="is-size-5 publication-authors">
                        <span class="author-block">
                          <sup>1</sup>Music and Audio Research Group (MARG),<br>
                          <sup>2</sup>IPAI,
                          <sup>3</sup>AIIS,
                          <sup>4</sup>Department of Intelligence and Information,<br>
                          Seoul National University
                        </span>
                        <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                      </div>
    
                      <div class="column has-text-centered">
                        <div class="publication-links">
                             <!-- Arxiv PDF link -->
                          <!-- <span class="link-block">
                            <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                            class="external-link button is-normal is-rounded is-dark">
                            <span class="icon">
                              <i class="fas fa-file-pdf"></i>
                            </span>
                            <span>Paper</span>
                          </a>
                        </span> -->
    
                        <!-- Supplementary PDF link -->
                        <!-- <span class="link-block">
                          <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                          class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">
                            <i class="fas fa-file-pdf"></i>
                          </span>
                          <span>Supplementary</span>
                        </a>
                      </span> -->
    
                      <!-- Github link -->
                      <span class="link-block">
                        <a href="https://github.com/yoongi43/MGE-LDM" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fab fa-github"></i>
                        </span>
                        <span>Code</span>
                      </a>
                    </span>
    
                    <!-- ArXiv abstract Link -->
                    <span class="link-block">
                      <a href="https://arxiv.org/abs/2505.23305" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv (TBD)</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
                We present MGE-LDM, a unified latent diffusion framework for simultaneous music generation, source imputation, and query-driven source separation.
                Unlike prior approaches constrained to fixed instrument classes, MGE-LDM learns a joint distribution over full mixtures, submixtures, and individual stems within a single compact latent diffusion model.
                At inference, MGE-LDM enables (1) complete mixture generation, (2) 
                partial generation (i.e., source imputation), and (3) text-conditioned extraction of arbitrary sources.
                By formulating both separation and imputation as conditional inpainting tasks in the latent space, our approach supports flexible, class-agnostic manipulation of arbitrary instrument sources.
                Notably, MGE-LDM can be trained jointly across heterogeneous multi-track datasets (e.g., Slakh2100, MUSDB18, MoisesDB) without relying on predefined instrument categories.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->


  <!-- Main Figure Section -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Proposed Method.</h2>
          <figure>
            <img src="static/images/figs_overall.png" alt="Overall Architecture Figure" style="max-width:100%; border-radius:16px; box-shadow: 0 0 24px #ccc;">
            <figcaption style="margin-top: 12px; font-size: 1.1em; color: #555;">
                (a) Training pipeline:
                We train a three-track latent diffusion model on mixtures, submixtures, and sources. 
                Each track is perturbed independently and conditioned on its corresponding timestep and CLAP embedding. 
                <!-- The model is optimized using the v-objective,
                as detailed in Sections 3.2 and 3.4.  -->
                (b) Inference pipeline: 
                At test time, task-specific latents are either
                generated or inpainted based on available context and text prompts. 
                The resulting latents are decoded into waveforms. 
                <!-- See Section 3.3 for details. -->
            </figcaption>
          </figure>
        </div>
      </div>
    </div>
  </section>
  <!-- End Main Figure Section -->
  

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Audio Demos for Slakh (Bass, Drums, Guitar, Piano only)</h2>
      <div class="buttons is-centered">
        <a href="total_generation.html" class="button btn-purple is-medium is-rounded">Total Generation</a>
        <a href="partial_generation.html" class="button btn-yellow is-medium is-rounded">Partial Generation</a>
        <a href="extraction.html" class="button btn-red is-medium is-rounded">Source Extraction</a>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Beyond Slakh: + MUSDB18 and MoisesDB</h2>
      <div class="buttons is-centered">
        <a href="full_total_generation.html" class="button btn-purple is-medium is-rounded">Total Generation (Full)</a>
        <a href="full_partial_generation.html" class="button btn-yellow is-medium is-rounded">Partial Generation (Full)</a>
        <a href="full_extraction_base.html" class="button btn-red is-medium is-rounded">Source Extraction (Full)</a>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Additional Real-World Audio Samples with MGE-LDM</h2>
      <div class="buttons is-centered">
        <a href="https://agreeable-diplodocus-5ca.notion.site/Additional-Real-World-Audio-Samples-with-MGE-LDM-23644c3c089d80cfb46bdf3aed1ffd8b?source=copy_link" 
        class="button btn-magenta is-medium is-rounded"
        target="_blank"
        rel="noopener"
        >Real World Samples</a>
      </div>
    </div>
  </section>

  <script>
    document.querySelectorAll('.js-player').forEach(el => {
      new Plyr(el, {
        controls: ['play', 'progress'], // 진행바+재생버튼만 (시간표시 없음!)
        // controls: ['play'] // 오직 play 버튼만
        // controls: ['play', 'progress', 'current-time', 'duration'] // 시간도 보고싶으면
      });
    });
  </script>
</body>